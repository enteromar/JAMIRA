Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	resistome_prediction
	1

[Wed Aug 28 20:19:41 2019]
rule resistome_prediction:
    input: data/samples/V583.fasta
    output: resistome_prediction/V583
    jobid: 0
    wildcards: sample=V583

docker run -v $PWD:/data -t quay.io/biocontainers/rgi:4.2.2--py35ha92aebf_1 rgi main -i data/data/samples/V583.fasta -o data/resistome_prediction/V583 -t contig --clean --debug > resistome_prediction/V583
[Wed Aug 28 20:21:42 2019]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /home/icaro/WGCA/.snakemake/log/2019-08-28T201941.526203.snakemake.log
