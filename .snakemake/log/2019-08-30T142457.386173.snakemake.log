Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	generate_resistome_heatmap_v2
	31	resistome_prediction
	32

[Fri Aug 30 14:24:57 2019]
rule resistome_prediction:
    input: data/samples/L8.fasta
    output: resistome_prediction/L8
    jobid: 31
    wildcards: sample=L8

Terminating processes on user request, this might take some time.
[Fri Aug 30 14:25:09 2019]
Error in rule resistome_prediction:
    jobid: 31
    output: resistome_prediction/L8
    shell:
        docker run -v $PWD:/data -t quay.io/biocontainers/rgi:4.2.2--py35ha92aebf_1 rgi main -i data/data/samples/L8.fasta -o data/resistome_prediction/L8 -t contig --clean --debug > resistome_prediction/L8
        (exited with non-zero exit code)

Removing output files of failed job resistome_prediction since they might be corrupted:
resistome_prediction/L8
Complete log: /home/icaro/WGCA/.snakemake/log/2019-08-30T142457.386173.snakemake.log
